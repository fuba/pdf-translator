"""Demo script to test post-processing functionality."""

import logging
from pathlib import Path

import yaml

from src.post_processor import PostProcessor, PostProcessorConfig
from src.term_miner import Term

# Setup logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def test_basic_annotation():
    """Test basic term annotation functionality."""
    print("\n=== Testing Basic Term Annotation ===")

    config = PostProcessorConfig()
    processor = PostProcessor(config)

    # Sample translated text with technical terms
    translated_text = """æ©Ÿæ¢°å­¦ç¿’ã¯äººå·¥çŸ¥èƒ½ã®ä¸€åˆ†é‡ã§ã™ã€‚
æ·±å±¤å­¦ç¿’ã¯æ©Ÿæ¢°å­¦ç¿’ã®æ‰‹æ³•ã®ä¸€ã¤ã§ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
è‡ªç„¶è¨€èªå‡¦ç†ã¯äººå·¥çŸ¥èƒ½ã®ã‚‚ã†ä¸€ã¤ã®é‡è¦ãªåˆ†é‡ã§ã™ã€‚"""

    # Term dictionary (original -> translation)
    term_dict = {
        "machine learning": "æ©Ÿæ¢°å­¦ç¿’",
        "artificial intelligence": "äººå·¥çŸ¥èƒ½",
        "deep learning": "æ·±å±¤å­¦ç¿’",
        "neural network": "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯",
        "natural language processing": "è‡ªç„¶è¨€èªå‡¦ç†",
    }

    result = processor.process(translated_text, term_dict)

    if result.success:
        print("âœ“ Post-processing successful")
        print(f"  Annotations added: {result.annotations_added}")
        print(f"  Terms processed: {result.terms_processed}")

        print("\nOriginal text:")
        print(translated_text)

        print("\nProcessed text:")
        print(result.processed_text)

        # Check for expected annotations
        expected_annotations = [
            "æ©Ÿæ¢°å­¦ç¿’ï¼ˆmachine learningï¼‰",
            "äººå·¥çŸ¥èƒ½ï¼ˆartificial intelligenceï¼‰",
            "æ·±å±¤å­¦ç¿’ï¼ˆdeep learningï¼‰",
            "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆneural networkï¼‰",
            "è‡ªç„¶è¨€èªå‡¦ç†ï¼ˆnatural language processingï¼‰",
        ]

        found_annotations = []
        for annotation in expected_annotations:
            if annotation in result.processed_text:
                found_annotations.append(annotation)

        print(f"\nFound annotations: {len(found_annotations)}/{len(expected_annotations)}")
        for annotation in found_annotations:
            print(f"  âœ“ {annotation}")

    else:
        print(f"âœ— Post-processing failed: {result.error}")
        return False

    return True


def test_first_occurrence_only():
    """Test that annotations are only added on first occurrence."""
    print("\n=== Testing First Occurrence Only ===")

    config = PostProcessorConfig()
    processor = PostProcessor(config)

    # Text with repeated terms
    translated_text = """æ©Ÿæ¢°å­¦ç¿’ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚
æ©Ÿæ¢°å­¦ç¿’ã¯é‡è¦ãªæŠ€è¡“ã§ã™ã€‚æ©Ÿæ¢°å­¦ç¿’ã®å¿œç”¨ä¾‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚
æ·±å±¤å­¦ç¿’ã‚‚æ©Ÿæ¢°å­¦ç¿’ã®ä¸€ç¨®ã§ã™ã€‚"""

    term_dict = {"machine learning": "æ©Ÿæ¢°å­¦ç¿’", "deep learning": "æ·±å±¤å­¦ç¿’"}

    result = processor.process(translated_text, term_dict)

    if result.success:
        print("âœ“ Processing successful")

        # Count occurrences
        annotated_ml = result.processed_text.count("æ©Ÿæ¢°å­¦ç¿’ï¼ˆmachine learningï¼‰")
        plain_ml = result.processed_text.count("æ©Ÿæ¢°å­¦ç¿’") - annotated_ml

        print(f"  æ©Ÿæ¢°å­¦ç¿’ï¼ˆmachine learningï¼‰: {annotated_ml} times")
        print(f"  æ©Ÿæ¢°å­¦ç¿’ (plain): {plain_ml} times")

        print("\nProcessed text:")
        print(result.processed_text)

        # Should have exactly one annotated occurrence
        if annotated_ml == 1:
            print("âœ“ Correct: Only first occurrence is annotated")
        else:
            print(f"âœ— Error: Expected 1 annotation, got {annotated_ml}")
            return False

    return True


def test_custom_format():
    """Test custom annotation formats."""
    print("\n=== Testing Custom Annotation Format ===")

    # Test different formats
    formats = [
        "{translation}ï¼ˆ{original}ï¼‰",  # Default Japanese style
        "{translation} [{original}]",  # Square brackets
        "{translation} ({original})",  # Regular parentheses
        "{translation}ã€{original}ã€",  # Japanese quotes
    ]

    translated_text = "æ©Ÿæ¢°å­¦ç¿’ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚"
    term_dict = {"machine learning": "æ©Ÿæ¢°å­¦ç¿’"}

    for fmt in formats:
        config = PostProcessorConfig(source_term_format=fmt)
        processor = PostProcessor(config)

        result = processor.process(translated_text, term_dict)

        if result.success:
            expected = fmt.format(translation="æ©Ÿæ¢°å­¦ç¿’", original="machine learning")
            if expected in result.processed_text:
                print(f"âœ“ Format '{fmt}' works: {expected}")
            else:
                print(f"âœ— Format '{fmt}' failed")
                return False
        else:
            print(f"âœ— Processing failed for format '{fmt}'")
            return False

    return True


def test_overlapping_terms():
    """Test handling of overlapping terms."""
    print("\n=== Testing Overlapping Terms ===")

    config = PostProcessorConfig()
    processor = PostProcessor(config)

    # Text with overlapping terms
    translated_text = "è‡ªç„¶è¨€èªå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚"

    # Overlapping terms: "è‡ªç„¶è¨€èª" vs "è‡ªç„¶è¨€èªå‡¦ç†"
    term_dict = {
        "natural language": "è‡ªç„¶è¨€èª",
        "natural language processing": "è‡ªç„¶è¨€èªå‡¦ç†",
        "system": "ã‚·ã‚¹ãƒ†ãƒ ",
    }

    result = processor.process(translated_text, term_dict)

    if result.success:
        print("âœ“ Processing successful")
        print(f"  Annotations added: {result.annotations_added}")

        print("\nProcessed text:")
        print(result.processed_text)

        # Should prefer longer term (è‡ªç„¶è¨€èªå‡¦ç† over è‡ªç„¶è¨€èª)
        if "è‡ªç„¶è¨€èªå‡¦ç†ï¼ˆnatural language processingï¼‰" in result.processed_text:
            print("âœ“ Correctly annotated longer term")
        else:
            print("âœ— Failed to prioritize longer term")
            return False

        # Should not have overlapping annotations
        if "è‡ªç„¶è¨€èªï¼ˆnatural languageï¼‰å‡¦ç†" in result.processed_text:
            print("âœ— Created overlapping annotations")
            return False
        else:
            print("âœ“ No overlapping annotations")

    return True


def test_spacing_adjustment():
    """Test spacing adjustment between Japanese and English."""
    print("\n=== Testing Spacing Adjustment ===")

    config = PostProcessorConfig(spacing_adjustment=True)
    processor = PostProcessor(config)

    # Text with mixed Japanese and English
    translated_text = (
        "ã“ã‚Œã¯APIï¼ˆApplication Programming Interfaceï¼‰ã®èª¬æ˜ã§ã™ã€‚JSONãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
    )
    term_dict = {}

    result = processor.process(translated_text, term_dict)

    if result.success:
        print("âœ“ Spacing adjustment successful")

        print("\nOriginal text:")
        print(translated_text)

        print("\nWith spacing adjustment:")
        print(result.processed_text)

        # Basic check - should have spaces around English terms
        if " API " in result.processed_text or " JSON " in result.processed_text:
            print("âœ“ Added appropriate spacing")
        else:
            print("âš ï¸  Spacing adjustment may not be working as expected")

    return True


def test_config_loading():
    """Test loading configuration from file."""
    print("\n=== Testing Configuration Loading ===")

    config_path = Path("config/config.yml")
    if not config_path.exists():
        print(f"âš ï¸  Config file not found: {config_path}")
        return True

    try:
        with open(config_path, "r") as f:
            full_config = yaml.safe_load(f)

        # Look for post-processing config (may not exist yet)
        post_config_dict = full_config.get(
            "post_processing",
            {
                "add_source_terms": True,
                "source_term_format": "{translation}ï¼ˆ{original}ï¼‰",
                "spacing_adjustment": True,
            },
        )

        config = PostProcessorConfig.from_dict(post_config_dict)
        PostProcessor(config)

        print("âœ“ Loaded configuration:")
        print(f"  Add source terms: {config.add_source_terms}")
        print(f"  Format: {config.source_term_format}")
        print(f"  Spacing adjustment: {config.spacing_adjustment}")

        return True

    except Exception as e:
        print(f"âœ— Failed to load config: {e}")
        return False


def test_with_term_objects():
    """Test processing with Term objects."""
    print("\n=== Testing with Term Objects ===")

    config = PostProcessorConfig()
    processor = PostProcessor(config)

    translated_text = "æ©Ÿæ¢°å­¦ç¿’ã¨æ·±å±¤å­¦ç¿’ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚"

    # Create Term objects
    terms = [
        Term("machine learning", 3, translations={"ja": "æ©Ÿæ¢°å­¦ç¿’"}),
        Term("deep learning", 2, translations={"ja": "æ·±å±¤å­¦ç¿’"}),
        Term("AI", 1, translations={"ja": "AI"}),  # Too short, should be filtered
    ]

    result = processor.process_with_terms(translated_text, terms)

    if result.success:
        print("âœ“ Processing with Term objects successful")
        print(f"  Annotations added: {result.annotations_added}")

        print("\nProcessed text:")
        print(result.processed_text)

        return True
    else:
        print(f"âœ— Processing failed: {result.error}")
        return False


def main():
    """Run all post-processing tests."""
    print("PDF Translation System - Post-Processing Demo")
    print("=" * 55)

    tests = [
        ("Basic Term Annotation", test_basic_annotation),
        ("First Occurrence Only", test_first_occurrence_only),
        ("Custom Annotation Format", test_custom_format),
        ("Overlapping Terms", test_overlapping_terms),
        ("Spacing Adjustment", test_spacing_adjustment),
        ("Configuration Loading", test_config_loading),
        ("Term Objects Processing", test_with_term_objects),
    ]

    results = []
    for test_name, test_func in tests:
        try:
            success = test_func()
            results.append((test_name, success))
            if success:
                print(f"\nâœ“ {test_name} passed!")
            else:
                print(f"\nâœ— {test_name} failed!")
        except Exception as e:
            print(f"\nâœ— {test_name} error: {str(e)}")
            results.append((test_name, False))

    # Summary
    print("\n" + "=" * 55)
    print("Test Summary:")
    passed = sum(1 for _, success in results if success)
    total = len(results)

    for test_name, success in results:
        status = "âœ“ PASSED" if success else "âœ— FAILED"
        print(f"  {status}: {test_name}")

    print(f"\nResult: {passed}/{total} tests passed")

    if passed == total:
        print("ğŸ‰ All post-processing tests completed successfully!")
    else:
        print("âš ï¸  Some tests failed. Check the output above for details.")


if __name__ == "__main__":
    main()
